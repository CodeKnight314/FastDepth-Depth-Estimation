import torch
import torch.nn as nn
import torch.nn.functional as F

class SSIM(nn.Module):
    def __init__(self, constants=(0.0001, 0.0001)):
        """
        Initializes the SSIM calculation Module. 

        Args: 
            constants (Tuple[Int, Int]): Constants (C1, C2) for stablizing SSIM calculation.
        """
        super().__init__()
        self.C1 = constants[0]
        self.C2 = constants[1]

    def channel_calculation(self, x, y):
        """
        Computes SSIM for a single channel of the images.

        Args:
            x (torch.Tensor): The first image channel.
            y (torch.Tensor): The second image channel.

        Returns:
            torch.Tensor: The SSIM value for the given channel.
        """
        mean_x = torch.mean(x)
        mean_y = torch.mean(y)
        
        variance_x = torch.var(x, unbiased=False)
        variance_y = torch.var(y, unbiased=False)
        
        covariance_xy = torch.mean((x - mean_x) * (y - mean_y))
        
        SSIM = ((2 * mean_x * mean_y + self.C1) * (2 * covariance_xy + self.C2)) / ((mean_x ** 2 + mean_y ** 2 + self.C1) * (variance_x + variance_y + self.C2))
        
        return SSIM

    def channel_splits(self, x, y):
        """
        Splits the images into individual channels and returns them as separate tensors.

        Args:
            x (torch.Tensor): The first image tensor with shape (N, C, H, W).
            y (torch.Tensor): The second image tensor with shape (N, C, H, W).

        Returns:
            (List[torch.Tensor], List[torch.Tensor]): Two lists containing the channels of x and y, respectively.
        """
        assert x.shape[1] == y.shape[1], "[ERROR] X and Y have different number of channels."

        x_tensors = []
        y_tensors = []

        for i in range(x.shape[1]):
            x_tensors.append(x[:, i, :, :])
            y_tensors.append(y[:, i, :, :])
        
        return x_tensors, y_tensors
    
    def forward(self, clean_img, sr_img):
        """
        Computes Structural Similarity Index (SSIM) between the clean (reference) image and the 
        super-resolved (SR) image.

        Args: 
            clean_img (torch.Tensor): The ground truth image.
            sr_img (torch.Tensor): The super-resolved image generated by the model.
        
        Returns: 
            torch.Tensor: The SSIM value

        """
        x_tensors, y_tensors = self.channel_splits(clean_img, sr_img)

        SSIM_values = 0.0
        for x, y in zip(x_tensors, y_tensors):
            SSIM_values += self.channel_calculation(x, y)
        
        final_ssim = 1 - SSIM_values / len(x_tensors) 
        return final_ssim

class FastDepthLoss(nn.Module):
    def __init__(self,
                 weight_scale: float = 1.0,
                 weight_edge: float = 1.0, 
                 weight_ssim: float = 1.0):

        super(FastDepthLoss, self).__init__()

        self.weight_scale = weight_scale
        self.weight_edge = weight_edge
        self.weight_ssim = weight_ssim
        
        self.sobel_x = nn.Parameter(torch.Tensor([[-1, 0, 1], 
                                                  [-2, 0, 2], 
                                                  [-1, 0, 1]]))
    
        self.sobel_y = nn.Parameter(torch.Tensor([[-1, -2, -1], 
                                                  [0, 0, 0], 
                                                  [1, 2, 1]]))
        
        self.conv_x = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)
        self.conv_x.weight = nn.Parameter(self.sobel_x.unsqueeze(0).unsqueeze(0))

        self.conv_y = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)
        self.conv_y.weight = nn.Parameter(self.sobel_y.unsqueeze(0).unsqueeze(0))
        
        self.ssim = SSIM()

    def scale_invariant_loss(self, pred: torch.Tensor, target: torch.Tensor):
        eps = 1e-6
        pred = torch.clamp(pred, min=eps)
        target = torch.clamp(target, min=eps)

        log_pred = torch.log(pred)
        log_target = torch.log(target)

        diff = log_pred - log_target
        mse_term = torch.mean(diff ** 2)
        bias_term = (torch.mean(diff) ** 2)

        loss = mse_term - 0.5 * bias_term
        return loss
    
    def edge_aware_loss(self, pred: torch.Tensor, target: torch.Tensor): 
        pred_grad_x = self.conv_x(pred)
        pred_grad_y = self.conv_y(pred)
        
        target_grad_x = self.conv_x(target)
        target_grad_y = self.conv_y(target)
        
        grad_loss = torch.sqrt(pred_grad_x**2 + pred_grad_y**2) - torch.sqrt(target_grad_x**2 + target_grad_y**2)
        return grad_loss.mean()

    def forward(self, pred: torch.Tensor, gt: torch.Tensor):
        si_loss = self.scale_invariant_loss(pred, gt)
        ed_loss = self.edge_aware_loss(pred, gt)
        ssim_loss = self.ssim(pred, gt)

        total_loss = self.weight_scale * si_loss + self.weight_edge * ed_loss + self.weight_ssim * ssim_loss

        return total_loss

def kl_divergence(prediction: torch.Tensor, target: torch.Tensor): 
    """
    Returns the KL-Divergence of prediction relative to the target distribution
    
    Args: 
        prediction (torch.Tensor): Predicted distribution as a 1D array
        target (torch.Tensor): Target distribution as a 1D array
        
    Returns: 
        (float): numerical distance between the two distributions.
    """
    eps = 1e-10
    
    prediction = prediction + eps 
    target = target + eps 
    
    return torch.sum(target * torch.log(target / prediction), dim=-1).mean().item()

if __name__ == "__main__":
    criterion = FastDepthLoss()

    x = torch.abs(torch.randn((16, 1, 256, 256), dtype=torch.float32))
    y = torch.abs(torch.randn((16, 1, 256, 256), dtype=torch.float32))

    loss = criterion(x, y)
    print(f"Total calculated loss for x and y is: {loss.item()}")